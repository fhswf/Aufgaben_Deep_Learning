{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textklassifikation mit RNN: GermEval 2018\n",
    "\n",
    "*GermEval* ‚Äì f√ºr German Evaluation ‚Äì ist ein j√§hrlicher Wettbewerb im Bereich Natural Language Processing f√ºr deutschsprachige Texte (s. [https://germeval.github.io/](https://germeval.github.io/)).\n",
    "\n",
    "Im Jahr 2018 ging es um die Erkennung von Beleidigungen in deutschsprachigen Tweets.\n",
    "\n",
    "In dieser Aufgabe wollen wir Rekurrente Neuronale Netze (RNN) zur Klassifikation nutzen. Zun√§chst einmal starten wir mit Vorarbeiten.\n",
    "\n",
    "## Format der Daten\n",
    "\n",
    "Die Trainings- und Testdaten liegen als mit Tabulatoren separierte Textdateien (Tab Separated Values ‚Äì TSV) vor. Uns interessieren die erste Spalte (der Tweet) und die zweite Spalte (`OFFENSE` f√ºr Beleidigung bzw. `OTHER` f√ºr keine Beleidigung).\n",
    "\n",
    "Der Befehl [`head`](https://wiki.ubuntuusers.de/head/) zeigt uns die ersten zeilen einer (Text-) Datei an, um folgenden Code Beispiel die ersten 10 Zeilen der Datei `germeval2018.training.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\tOTHER\tOTHER\n",
      "@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\tOTHER\tOTHER\n",
      "@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\tOTHER\tOTHER\n",
      "@dushanwegner Amis h√§tten alles und jeden gew√§hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\tOTHER\tOTHER\n",
      "@spdde kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\tOFFENSE\tINSULT\n",
      "@Dirki_M Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\tOTHER\tOTHER\n",
      "@milenahanm 33 bis 45 habe ich noch gar nicht gelebt und es geht mir am Arsch vorbei was in dieser Zeit geschehen ist. Ich lebe im heute und jetzt und nicht in der Vergangenheit.\tOFFENSE\tPROFANITY\n",
      "@jayxderxmensch @jayxthexhuman Wieso? Was findest du da unklar?\tOTHER\tOTHER\n",
      "@tagesschau Euere AfD Hetze wirkt. Da k√∂nnt ihr stolz sein bei #ARD-Fernsehen\tOFFENSE\tABUSE\n",
      "Deutsche Medien, Halbwahrheiten und einseitige Betrachtung, wie bei allen vom Staat finanzierten \"billigen\" Propagandainstitutionen üòú\tOFFENSE\tABUSE\n"
     ]
    }
   ],
   "source": [
    "! head -10 texts/germeval2018.training.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesen der Daten\n",
    "\n",
    "F√ºr das Einlesen der Datens√§tze verwenden wir die Klasse [`NamedTuple`](https://docs.python.org/3/library/collections.html#collections.namedtuple), mit der sich die Daten einfach speichern lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Record = namedtuple('Record', [ 'text', 'primary_label', 'secondary_label' ])\n",
    "\n",
    "with open('texts/germeval2018.training.tsv', 'r') as file:\n",
    "    training_data = [ Record(*line[:-1].split('\\t')) for line in file ]\n",
    "\n",
    "with open('texts/germeval2018.test.tsv', 'r') as file:\n",
    "    test_data = [ Record(*line[:-1].split('\\t')) for line in file ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.1 Sichtung der Daten\n",
    "\n",
    "Geben Sie die ersten f√ºnf Trainingsdatens√§tze aus.\n",
    "\n",
    "Welche Besonderheiten fallen Ihnen auf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √úberblick √ºber die Daten\n",
    "\n",
    "Wir schauen uns die Verteilung der Kategorien in den Trainings- und Testdaten an.\n",
    "\n",
    "### Aufgabe 1.2 Statistik der Trainings- und Testdaten\n",
    "\n",
    "Z√§hlen Sie mithilfe der Klasse [`Counter`](https://docs.python.org/3/library/collections.html) a us dem [`Collections`](https://docs.python.org/3/library/collections.html) Modul die Beleidigungen in den Trainings- und Testdaten. Unterscheiden sich Test- und Trainingsdaten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation von SpaCy\n",
    "\n",
    "Zur Vektorisierung der Texte verwenden wir vortrainierte Word Embeddings von [SpaCy](https://spacy.io/).\n",
    "\n",
    "Nachfolgend installieren wir daher [`torchtext`](https://pypi.org/project/torchtext/) und f√ºr die Erzeugung von Wortvektoren die [`de_core_news_md` Pipeline](https://spacy.io/models/de#de_core_news_md) des [natural language prpcessing (NLP)](https://de.wikipedia.org/wiki/Computerlinguistik) Moduls [SpaCy](https://spacy.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download de_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing der Tweets\n",
    "\n",
    "F√ºr die weitere Verarbeitung wollen wir Twitter Handles (`@username`) l√∂schen und das Hashtag-Zeichen entfernen. Damit verhindern wir, dass unser Model sp√§ter die Namen auswendig lernt, um die Daten zu klassifizieren. \n",
    "\n",
    "### Aufgabe 1.3 Aufbereitung der Tweets\n",
    "\n",
    "Bereiten Sie die Texte wie folgt auf:\n",
    "\n",
    "- Twitter Handles, d.h. Worte, die mit `@` beginnen, werden entfernt,\n",
    "- das Hashtag-Zeichen `#` sowie Anf√ºhrungszeichen werden entfernt,\n",
    "- Bindestriche `-` werden durch Leerzeichen ersetzt (warum ist das sinnvoll?).\n",
    "\n",
    "*Tipp: F√ºr die ersten beiden Schritte sind Regular Expressions hilfreich*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(text):\n",
    "    \"\"\" Preprocess a tweet. \"\"\"\n",
    "    \n",
    "    # remove handles, i.e. @username\n",
    "    # remove hashtags, quotes, etc.\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return text\n",
    "\n",
    "clean_tweet(training_data[4].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vektorisierung mit vortrainierten Wortvektoren\n",
    "\n",
    "Wir nutzen vortrainierte Wortvektoren aus Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_md\")\n",
    "\n",
    "def vectorize(text):\n",
    "    \"\"\"Vectorize text using the German SpaCy tokenizer\"\"\"\n",
    "    return torch.Tensor(np.array([tok.vector for tok in nlp(clean_tweet(text)) if tok.has_vector ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.4 Test der Vektorisierung\n",
    "\n",
    "Vektorisieren Sie den ersten Trainingsdatensatz. Welche Dimension haben die Wortvektoren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Daten\n",
    "\n",
    "Mithilfe der Funktion `vectorize()` definieren wir die Funktion `collate_batch()`, die einen Batch in zwei Tensoren ‚Äì f√ºr die Label und die Texte ‚Äì umwandelt.\n",
    "Damit wir das RNN sp√§ter effizient trainieren k√∂nnen, bringen wir die Text-Tensoren mithilfe der Funktion `pad_sequence()` auf die gleiche L√§nge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "LABEL = { 'OFFENSE': 1, 'OTHER': 0 }\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    \n",
    "    for record in batch:\n",
    "        label_list.append(LABEL[record.primary_label])\n",
    "        processed_text = vectorize(record.text)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.shape[0])\n",
    "    return torch.tensor(label_list), pad_sequence(text_list, batch_first=True), lengths\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, num_workers=5, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=5, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.5 Test des DataLoaders\n",
    "\n",
    "Was gibt der `DataLoader` zur√ºck? Haben die Tensoren bei jedem Batch die gleiche Form? Woran liegt das? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation von Text mittels RNNs\n",
    "\n",
    "Texte bestehen aus einer *Folge* von W√∂rtern. \n",
    "Rekurrente Neuronale Netze (RNNs) eignen sich gut f√ºr die Verarbeitung von Folgen.\n",
    "\n",
    "Unser Netz wird dabei aus zwei Schichten bestehen:\n",
    "1. das eigentliche RNN aus *Long-Short-Term-Memoy (LSTM)* Zellen oder *Gated Recurrent Units (GRU)*, die die Wortfolge auf eine Folge von *Zust√§nden* abbilden,\n",
    "2. einen linearen Layer, der den letzten Zustand auf eine eindimensionale Variable abbildet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufbau des RNNs\n",
    "\n",
    "Nun bauen wir das oben beschriebene Netz aus Embedding Layer, RNN Layer und Linear Layer auf.\n",
    "\n",
    "Die Funktionen `torch.nn.utils.rnn.pack_padded_sequence` und `torch.nn.utils.rnn.pad_packed_sequence` packen bzw. entpacken die Tensoren f√ºr eine effiziente Berechnung.\n",
    "**Wir strukturieren die Daten so, dass Batch die erste Dimension ist (`batch_first = True`)**.\n",
    "\n",
    "### Aufgabe 1.6 Definition der Netzwerkschichten\n",
    "\n",
    "Das RNN soll folgende Struktur haben:\n",
    "\n",
    "- Ein `GRU` mit drei Schichten der Gr√∂√üe `hidden_dim` und dem definierten Dropout,\n",
    "- ein `Linear` Layer, der die Daten auf zwei Dimensionen reduziert.\n",
    "\n",
    "**Beachten Sie, dass wir zur Textklassifikation die Ausgabe zum letzten Token verwenden.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class RNN(torch.nn.Module) :\n",
    "    def __init__(self, hidden_dim, embedding_dim = 300, dropout = 0.4) :\n",
    "        super().__init__()\n",
    "  \n",
    "        self.gru = None    # YOUR CODE HERE\n",
    "        self.linear =None  # YOUR CODE HERE    \n",
    "        \n",
    "    def forward(self, _x, **kwargs):\n",
    "        (x, input_lengths) = _x\n",
    "        \n",
    "        x = pack_padded_sequence(x, input_lengths, batch_first=True, enforce_sorted=False)\n",
    "       \n",
    "        # Apply GRU\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        x, output_lengths = pad_packed_sequence(x, batch_first=True)\n",
    "        out = None # YOUR CODE HERE \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training und Validierung\n",
    "\n",
    "### Aufgabe 1.7 Z√§hlen der Parameter\n",
    "\n",
    "Die Funktion `count_parameters(model)` soll die Zahl der trainierbaren Parameter des Models zur√ºckgeben.\n",
    "\n",
    "Hinweis: In [√úbung 1 - Aufgabe 1 - Erkennung von Mode](https://github.com/fhswf/Aufgaben_Deep_Learning/blob/main_with_solution/Veranstaltung_1/Aufgabe_1/L%C3%B6sung_1.ipynb) haben wir bereits Code kennen gelernt, wie wir die Parameter eines Modells z√§hlen k√∂nnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    # YOUR CODE HERE\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(hidden_dim=64, dropout=0.5)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.8 Training\n",
    "\n",
    "Diskutieren sie die folgende Trainings- und Validierungsschleife in ihren Gruppen. Ist die Funktionsweise klar?\n",
    "F√ºhren Sie das Training f√ºr verschiedene Werte von `hidden_dim`, `dropout` und mit unterschiedlichen Lern¬¥raten durch. \n",
    "\n",
    "Was ist die beste Accuracy, die Sie erreichen?\n",
    "\n",
    "### Aufgabe 1.9 Erweiterte Metriken\n",
    "\n",
    "Bestimmen Sie zus√§tzlich zur Accuracy *Precision*, *Recall* und *F-Score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer=torch.optim.AdamW(model.parameters(), lr=0.0005)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "epochs = 10 \n",
    "training_loss = []\n",
    "testing_loss = []\n",
    "training_acc = []\n",
    "testing_acc = []\n",
    "\n",
    "\n",
    "with tqdm(range(epochs)) as iterator:\n",
    "    for epoch in iterator:\n",
    "\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0     \n",
    "        for idx, (target, text, length) in enumerate(train_dataloader):\n",
    "\n",
    "            target, text = target.to(device), text.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            output = model((text, length))\n",
    "\n",
    "            loss = loss_fn(output, target) \n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss_fn(output, target).item()\n",
    "            predictions = output.data.max(1)[1]\n",
    "            train_acc += (predictions == target).sum().item()\n",
    " \n",
    "        training_acc.append(train_acc/len(train_dataloader.dataset))\n",
    "        training_loss.append(train_loss/len(train_dataloader.dataset))\n",
    "            \n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for target, text, length in test_dataloader:\n",
    "                target, text = target.to(device), text.to(device)\n",
    "                output = model((text, length))\n",
    "                loss = loss_fn(output, target)\n",
    "                prediction = torch.argmax(output, 1)\n",
    "                test_acc += (prediction == target).sum().item()\n",
    "                test_loss += loss.item()        \n",
    "                \n",
    "            testing_acc.append(test_acc/len(test_dataloader.dataset))\n",
    "            testing_loss.append(test_loss/len(test_dataloader.dataset))\n",
    "            \n",
    "        loss = running_loss/count\n",
    "        accuracy = 100. * running_correct/count \n",
    "        iterator.set_postfix_str(f\"train_acc: {train_acc/len(train_dataloader.dataset):.2f} test_acc: {test_acc/len(test_dataloader.dataset):.2f} train_loss: {train_loss/len(train_dataloader.dataset):.2e} test_loss: {test_loss/len(test_dataloader.dataset):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
