{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textklassifikation mit RNN: GermEval 2018\n",
    "\n",
    "*GermEval* â€“ fÃ¼r German Evaluation â€“ ist ein jÃ¤hrlicher Wettbewerb im Bereich Natural Language Processing fÃ¼r deutschsprachige Texte (s. [https://germeval.github.io/](https://germeval.github.io/)).\n",
    "\n",
    "Im Jahr 2018 ging es um die Erkennung von Beleidigungen in deutschsprachigen Tweets.\n",
    "\n",
    "In dieser Aufgabe wollen wir Rekurrente Neuronale Netze (RNN) zur Klassifikation nutzen. ZunÃ¤chst einmal starten wir mit Vorarbeiten.\n",
    "\n",
    "## Format der Daten\n",
    "\n",
    "Die Trainings- und Testdaten liegen als mit Tabulatoren separierte Textdateien (Tab Separated Values â€“ TSV) vor. Uns interessieren die erste Spalte (der Tweet) und die zweite Spalte (`OFFENSE` fÃ¼r Beleidigung bzw. `OTHER` fÃ¼r keine Beleidigung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@corinnamilborn Liebe Corinna, wir wÃ¼rden dich gerne als Moderatorin fÃ¼r uns gewinnen! WÃ¤rst du begeisterbar?\tOTHER\tOTHER\n",
      "@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverstÃ¤ndlich. Dass das BVerfG Sachleistungen nicht ausschlieÃŸt, kritisieren wir.\tOTHER\tOTHER\n",
      "@ahrens_theo frÃ¶hlicher gruÃŸ aus der schÃ¶nsten stadt der welt theo âš“ï¸\tOTHER\tOTHER\n",
      "@dushanwegner Amis hÃ¤tten alles und jeden gewÃ¤hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\tOTHER\tOTHER\n",
      "@spdde kein verlÃ¤ÃŸlicher Verhandlungspartner. Nachkarteln nach den SondierzngsgesprÃ¤chen - schickt diese StÃ¼mper #SPD in die Versenkung.\tOFFENSE\tINSULT\n",
      "@Dirki_M Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. GeschÃ¼tzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bemÃ¼ht - Ã¼brigens leicht rÃ¼cklÃ¤ufig gewesen.\tOTHER\tOTHER\n",
      "@milenahanm 33 bis 45 habe ich noch gar nicht gelebt und es geht mir am Arsch vorbei was in dieser Zeit geschehen ist. Ich lebe im heute und jetzt und nicht in der Vergangenheit.\tOFFENSE\tPROFANITY\n",
      "@jayxderxmensch @jayxthexhuman Wieso? Was findest du da unklar?\tOTHER\tOTHER\n",
      "@tagesschau Euere AfD Hetze wirkt. Da kÃ¶nnt ihr stolz sein bei #ARD-Fernsehen\tOFFENSE\tABUSE\n",
      "Deutsche Medien, Halbwahrheiten und einseitige Betrachtung, wie bei allen vom Staat finanzierten \"billigen\" Propagandainstitutionen ğŸ˜œ\tOFFENSE\tABUSE\n"
     ]
    }
   ],
   "source": [
    "! head -10 texts/germeval2018.training.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesen der Daten\n",
    "\n",
    "FÃ¼r das Einlesen der DatensÃ¤tze verwenden wir die Klasse `NamedTuple`, mit der sich die Daten einfach speichern lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Record(text='@corinnamilborn Liebe Corinna, wir wÃ¼rden dich gerne als Moderatorin fÃ¼r uns gewinnen! WÃ¤rst du begeisterbar?', primary_label='OTHER', secondary_label='OTHER'),\n",
       " Record(text='@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverstÃ¤ndlich. Dass das BVerfG Sachleistungen nicht ausschlieÃŸt, kritisieren wir.', primary_label='OTHER', secondary_label='OTHER'),\n",
       " Record(text='@ahrens_theo frÃ¶hlicher gruÃŸ aus der schÃ¶nsten stadt der welt theo âš“ï¸', primary_label='OTHER', secondary_label='OTHER'),\n",
       " Record(text='@dushanwegner Amis hÃ¤tten alles und jeden gewÃ¤hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!', primary_label='OTHER', secondary_label='OTHER'),\n",
       " Record(text='@spdde kein verlÃ¤ÃŸlicher Verhandlungspartner. Nachkarteln nach den SondierzngsgesprÃ¤chen - schickt diese StÃ¼mper #SPD in die Versenkung.', primary_label='OFFENSE', secondary_label='INSULT')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Record = namedtuple('Record', [ 'text', 'primary_label', 'secondary_label' ])\n",
    "\n",
    "with open('texts/germeval2018.training.tsv', 'r') as file:\n",
    "    training_data = [ Record(*line[:-1].split('\\t')) for line in file ]\n",
    "\n",
    "with open('texts/germeval2018.test.tsv', 'r') as file:\n",
    "    test_data = [ Record(*line[:-1].split('\\t')) for line in file ]\n",
    "\n",
    "training_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ãœberblick Ã¼ber die Daten\n",
    "\n",
    "Wir schauen uns die Verteilung der Kategorien in den Trainings- und Testdaten an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('OTHER', 'OTHER'): 3321,\n",
       "         ('OFFENSE', 'INSULT'): 595,\n",
       "         ('OFFENSE', 'PROFANITY'): 71,\n",
       "         ('OFFENSE', 'ABUSE'): 1022})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter([ (record.primary_label, record.secondary_label) for record in training_data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('OTHER', 'OTHER'): 2330,\n",
       "         ('OFFENSE', 'ABUSE'): 773,\n",
       "         ('OFFENSE', 'INSULT'): 381,\n",
       "         ('OFFENSE', 'PROFANITY'): 48})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([ (record.primary_label, record.secondary_label) for record in test_data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.14.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy\n",
      "  Downloading spacy-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext) (2.28.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext) (1.22.4)\n",
      "Collecting torch==1.13.0\n",
      "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m887.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext) (4.64.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.13.0->torchtext) (4.3.0)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchtext) (65.3.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchtext) (0.37.1)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (806 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m806.5/806.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.10\n",
      "  Using cached spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (491 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.2-py3-none-any.whl (42 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Collecting smart-open<6.0.0,>=5.2.1\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (2022.6.15.1)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.3-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: wasabi, cymem, typer, spacy-loggers, spacy-legacy, smart-open, pydantic, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, murmurhash, langcodes, catalogue, blis, srsly, preshed, pathy, nvidia-cudnn-cu11, torch, confection, torchtext, thinc, spacy\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu116\n",
      "    Uninstalling torch-1.12.1+cu116:\n",
      "      Successfully uninstalled torch-1.12.1+cu116\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu116 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
      "torchaudio 0.12.1+cu116 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.3 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pathy-0.6.2 preshed-3.0.8 pydantic-1.10.2 smart-open-5.2.1 spacy-3.4.2 spacy-legacy-3.0.10 spacy-loggers-1.0.3 srsly-2.4.5 thinc-8.1.5 torch-1.13.0 torchtext-0.14.0 typer-0.4.2 wasabi-0.10.1\n",
      "Collecting de-core-news-md==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_md-3.4.0/de_core_news_md-3.4.0-py3-none-any.whl (44.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from de-core-news-md==3.4.0) (3.4.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (8.1.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (3.1.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (4.64.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (2.28.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (1.10.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (1.22.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (65.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (2022.6.15.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (1.26.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-md==3.4.0) (2.1.1)\n",
      "Installing collected packages: de-core-news-md\n",
      "Successfully installed de-core-news-md-3.4.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext spacy\n",
    "!python -m spacy download de_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing der Tweets\n",
    "\n",
    "FÃ¼r die weitere Verarbeitung wollen wir Twitter Handles (`@username`) lÃ¶schen und das Hashtag-Zeichen entfernen. Damit verhindern wir, dass unser Model spÃ¤ter die Namen auswendig lernt, um die Daten zu klassifizieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' kein verlÃ¤ÃŸlicher Verhandlungspartner. Nachkarteln nach den SondierzngsgesprÃ¤chen   schickt diese StÃ¼mper SPD in die Versenkung.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(text):\n",
    "    \"\"\" Preprocess and tokenize a tweet. \"\"\"\n",
    "    \n",
    "    # remove handles, i.e. @username\n",
    "    text = re.sub('\\@\\w+', '', text)\n",
    "    # remove hashtags, quotes, etc.\n",
    "    text = re.sub('[\\#\"\\']+', '', text)\n",
    "    text = text.replace('-', ' ')\n",
    "    return text\n",
    "\n",
    "clean_tweet(training_data[4].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vektorisierung mit vortrainierten Wortvektoren\n",
    "\n",
    "Wir nutzen vortrainierte Wortvektoren aus Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_md\")\n",
    "\n",
    "def vectorize(text):\n",
    "    \"\"\"Vectorize text using the German SpaCy tokenizer\"\"\"\n",
    "    return torch.Tensor(np.array([tok.vector for tok in nlp(clean_tweet(text)) if tok.has_vector ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 300])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize(training_data[0].text).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Daten\n",
    "\n",
    "Mithilfe der Funktion `vectorize()` definieren wir die Funktion `collate_batch()`, die einen Batch in zwei Tensoren â€“ fÃ¼r die Label und die Texte â€“ umwandelt.\n",
    "Damit wir das RNN spÃ¤ter effizient trainieren kÃ¶nnen, bringen wir die Text-Tensoren mithilfe der Funktion `pad_sequence()` auf die gleiche LÃ¤nge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "LABEL = { 'OFFENSE': 1, 'OTHER': 0 }\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    \n",
    "    for record in batch:\n",
    "        label_list.append(LABEL[record.primary_label])\n",
    "        processed_text = vectorize(record.text)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.shape[0])\n",
    "    return torch.tensor(label_list), pad_sequence(text_list, batch_first=True), lengths\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, num_workers=5, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=5, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64]), torch.Size([64, 51, 300]), 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, texts, lengths = next(iter(train_dataloader))\n",
    "labels.shape, texts.shape, len(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation von Text mittels RNNs\n",
    "\n",
    "Texte bestehen aus einer *Folge* von WÃ¶rtern. \n",
    "Rekurrente Neuronale Netze (RNNs) eignen sich gut fÃ¼r die Verarbeitung von Folgen.\n",
    "\n",
    "Unser Netz wird dabei aus zwei Schichten bestehen:\n",
    "1. das eigentliche RNN aus *Long-Short-Term-Memoy (LSTM)* Zellen oder *Gated Recurrent Units (GRU)*, die die Wortfolge auf eine Folge von *ZustÃ¤nden* abbilden,\n",
    "2. einen linearen Layer, der den letzten Zustand auf eine eindimensionale Variable abbildet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufbau des RNNs\n",
    "\n",
    "Nun bauen wir das oben beschriebene Netz aus Embedding Layer, RNN Layer und Linear Layer auf.\n",
    "\n",
    "Die Funktionen `torch.nn.utils.rnn.pack_padded_sequence` und `torch.nn.utils.rnn.pad_packed_sequence` packen bzw. entpacken die Tensoren fÃ¼r eine effiziente Berechnung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class RNN(torch.nn.Module) :\n",
    "    def __init__(self, hidden_dim = 20, embedding_dim = 300, dropout = 0.4) :\n",
    "        super().__init__()\n",
    "  \n",
    "        #self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, dropout=0.1, batch_first=True)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=3, dropout=dropout, batch_first=True, bidirectional=False)\n",
    "        self.linear = nn.Linear(hidden_dim, 2)\n",
    "    \n",
    "        \n",
    "    def forward(self, _x, **kwargs):\n",
    "        (x, input_lengths) = _x\n",
    "        \n",
    "        x = pack_padded_sequence(x, input_lengths, batch_first=True, enforce_sorted=False)\n",
    "        #x, (ht, ct) = self.lstm(x)\n",
    "        x, ht = self.gru(x)\n",
    "        x, output_lengths = pad_packed_sequence(x, batch_first=True)\n",
    "        #print(ht[-1].shape)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training und Validierung\n",
    "\n",
    "Der Einfachheit halber verwenden wir fÃ¼r Training und Validierung weiterhin Scikit Learn und binden das RNN als `skorch.NeuralNetBinaryClassifier` ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(hidden_dim=64, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120322"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer=torch.optim.AdamW(model.parameters(), lr=0.0005)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e35d6f368f4087956f3df63b1bc657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "epochs = 10 \n",
    "training_loss = []\n",
    "testing_loss = []\n",
    "training_acc = []\n",
    "testing_acc = []\n",
    "\n",
    "\n",
    "with tqdm(range(epochs)) as iterator:\n",
    "    for epoch in iterator:\n",
    "\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0     \n",
    "        \n",
    "        for idx, (target, text, length) in enumerate(train_dataloader):\n",
    "\n",
    "            target, text = target.to(device), text.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            output = model((text, length))\n",
    "\n",
    "            loss = loss_fn(output, target) \n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss_fn(output, target).item()\n",
    "            predictions = output.data.max(1)[1]\n",
    "            train_acc += (predictions == target).sum().item()\n",
    " \n",
    "        training_acc.append(train_acc/len(train_dataloader.dataset))\n",
    "        training_loss.append(train_loss/len(train_dataloader.dataset))\n",
    "            \n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for target, text, length in test_dataloader:\n",
    "                target, text = target.to(device), text.to(device)\n",
    "                output = model((text, length))\n",
    "                loss = loss_fn(output, target)\n",
    "                prediction = torch.argmax(output, 1)\n",
    "                test_acc += (prediction == target).sum().item()\n",
    "                test_loss += loss.item()        \n",
    "                \n",
    "            testing_acc.append(test_acc/len(test_dataloader.dataset))\n",
    "            testing_loss.append(test_loss/len(test_dataloader.dataset))\n",
    "            \n",
    "        #loss = running_loss/count\n",
    "        #accuracy = 100. * running_correct/count \n",
    "        iterator.set_postfix_str(f\"train_acc: {train_acc/len(train_dataloader.dataset):.2f} test_acc: {test_acc/len(test_dataloader.dataset):.2f} train_loss: {train_loss/len(train_dataloader.dataset):.2e} test_loss: {test_loss/len(test_dataloader.dataset):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
