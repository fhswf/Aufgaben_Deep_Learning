{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0387b9fb-b552-4f3f-82c9-2160b9127844",
   "metadata": {},
   "source": [
    "# Autoencoder & Variational Autoencoder am Beispiel von FashionMNIST\n",
    "\n",
    "In dieser Aufgabe geht es darum, einen Autoencoder und einen Variational Autoencoder für den *FashionMNIST* Datensatz zu trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52acda6e-de44-4042-81df-fddcb6b161af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5c33c-a552-4fda-9f62-ac350baccb6c",
   "metadata": {},
   "source": [
    "## Daten laden\n",
    "\n",
    "Zunächst laden wir wieder die Trainings- und Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618144e7-069d-4818-8f21-44b645b60075",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "transform_image = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "trainset = FashionMNIST('/tmp/data', download=True, transform=transform_image, train=True)\n",
    "testset  = FashionMNIST('/tmp/data', download=True, transform=transform_image, train=False)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, num_workers=20, shuffle=True)\n",
    "test_loader  = DataLoader(testset, batch_size=batch_size, num_workers=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed42593-b820-41d6-ac30-425e608b5413",
   "metadata": {},
   "source": [
    "## Autoencoder: Definition des Encoders und Decoders\n",
    "\n",
    "Der *Encoder* transformiert jedes Bild (28x28 Pixel) in einen *latenten Raum* von niedriger Dimension. Die Dimension dieses Raumes sollten Sie als Parameter `latent_size` übergeben, damit wir die Größe später variieren können.\n",
    "\n",
    "Als Architektur können Sie in Ihren Gruppen zwei Ansätze ausprobieren:\n",
    "\n",
    "- Ein einfaches Netz bestehend aus zwei `Linear` Layern mit `ReLU` als Aktivierungsfunktion\n",
    "- Ein mehrschichtiges CNN mit drei Blöcken aus `Conv2d`, `BatchNorm2d` und `ReLU`. Wie in der Aufgabe zur Bildklassifikation \n",
    "  sollten Sie dabei die Zahl der Pixel verringern und die Zahl der Kanäle erhöhen. Am Ende hängen Sie einen `Linear` Layer an, der das Bild in \n",
    "  den latenten Raum transferiert.\n",
    "  \n",
    "Der *Decoder* besteht aus der umgekehrten Architektur (Tipp: `Conv2d` können Sie mit `ConvTranspose2d` \"umdrehen\") wie der *Encoder*.\n",
    "\n",
    "**Welche Aktivierungsfunktion sollten Sie am Ende verwenden, um Grauwerte im Bereich zwischen 0 und 1 zu erzeugen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250335a-3d97-4cb0-82dc-d5f36561857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        ## YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## YOUR CODE HERE\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        ## YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## YOUR CODE HERE\n",
    "        return x\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(latent_size)\n",
    "        self.decoder = Decoder(latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01dd085-dcef-47da-b039-88833d49c443",
   "metadata": {},
   "source": [
    "Die folgende Hilfsfunktion verwenden wir bei der Kontrollausgabe der Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2ff50-e6e2-4842-b59e-fd8998ee2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(x):\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab301b7-8af6-44fc-bf4f-d84a719ff0f4",
   "metadata": {},
   "source": [
    "## Vorbereitung des Trainings\n",
    "\n",
    "Zum Training wählen Sie eine geeignete `latent_size`, eine Verlustfunktion `criterion` und einen Optimizer aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9635344a-ea0e-4bbf-9eaf-6111fcd67410",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_epochs = 31\n",
    "latent_size = ## YOUR CODE HERE\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Autoencoder(latent_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = ## YOUR CODE HERE\n",
    "optimizer = ## YOUR CODE HERE\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383aab5d-86f5-46b7-91a9-f1a22c59171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(range(number_epochs)) as iterator:\n",
    "    for epoch in iterator:\n",
    "        running_loss = 0\n",
    "        count = 0\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            image, i = data\n",
    "            image = image.to(device)\n",
    "  \n",
    "            # Forward pass\n",
    "            output = model(image)\n",
    "            loss = criterion(output, image)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            count += 1\n",
    "        train_loss.append(running_loss/count)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_loss = 0\n",
    "            count = 0\n",
    "            for data in test_loader:\n",
    "                image, i = data\n",
    "                image = image.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(image)\n",
    "                loss = criterion(output, image)\n",
    "                running_loss += loss.item()\n",
    "                count += 1\n",
    "            test_loss.append(running_loss/count)\n",
    "                \n",
    "            iterator.set_postfix_str(f\"Train Loss: {train_loss[-1]:.4f}, Test Loss: {test_loss[-1]:.4f}\")\n",
    "            if epoch % 10 == 0:\n",
    "                rec = to_image(output.cpu().data)\n",
    "                img = to_image(image.cpu().data)\n",
    "                save_image(rec, f\"rec_{epoch}.png\")\n",
    "                save_image(img, f\"img_{epoch}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d5673-6352-42f2-923d-17cce55970cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss)), train_loss, label=\"train_loss\")\n",
    "plt.plot(range(len(test_loss)), test_loss, label=\"test_loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf461e-6ccc-4d88-a435-e9dcc623cf7b",
   "metadata": {},
   "source": [
    "## Teil 2: Variational Autoencoder\n",
    "\n",
    "Beim Variational Autoencoder erzeugt der *Encoder* zu einer Eingabe keinen festen Ausgabevektor, sondern eine Normalverteilung $N(\\mu, \\sigma)$.\n",
    "Der Encoder liefert dazu zwei Werte $\\mu$ und $\\log(\\sigma),$ die jeweils die Dimension `latent_size` haben.\n",
    "\n",
    "Mit diesen Parametern \"würfelt\" der Autoencoder einen Wert, den er dann an den *Decoder* übergibt. Dazu dient die Methode `reparametrize`\n",
    "\n",
    "Die Verlustfunktion setzt sich dann aus dem Rekonstruktionsverlust $D_{RL}$ und der *Kullback-Leibler Divergenz* der Verteilung zur Standardnormalverteilung \n",
    "\n",
    "$$D_{KL}[N(\\mu, \\sigma), N(0, 1)] = -\\frac{1}{2} \\sum(1+ log(\\sigma^2) - \\mu^2 - \\sigma^2)$$\n",
    "\n",
    "zusammen:\n",
    "\n",
    "$$D = D_{RL} + \\beta D_{KL}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ada25798-70b2-4fcc-a415-c1abc1116830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        ## YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## YOUR CODE HERE \n",
    "        return mu, logvar\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        ## YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## YOUR CODE HERE\n",
    "        return x\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = Encoder(latent_size)\n",
    "        self.decoder = Decoder(latent_size)\n",
    "        \n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.FloatTensor(std.size()).normal_().to(device)\n",
    "        return eps.mul(std).add_(mu)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        x = self.reparametrize(mu, logvar)\n",
    "        x = self.decoder(x)\n",
    "        return x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96f5dc-026f-49a7-adb2-c3a6c8191be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDLoss(nn.Module):\n",
    "    \"\"\"Calculate Kullback-Leibler divergence between learned mean and logvar and standard normal distribution.\n",
    "    This is *NOT* a re-implementation of torch.nn.KLDivLoss\"\"\"\n",
    "    def __init__(self, reduction='sum'):\n",
    "        super(KLDLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, mean, logvar):\n",
    "        # KLD loss\n",
    "        kld_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp(), 1)\n",
    "        # Size average\n",
    "        if self.reduction == 'mean':\n",
    "            kld_loss = torch.mean(kld_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            kld_loss = torch.sum(kld_loss)\n",
    "        return kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f972e72-cf78-4cfe-a0fc-ec3d5e3d308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_epochs = 31\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "beta = ## YOUR CODE HERE\n",
    "\n",
    "model = VariationalAutoencoder(latent_size)\n",
    "model = model.to(device)\n",
    "\n",
    "reconstruction_loss = ## YOUR CODE HERE\n",
    "kld_loss = ## YOUR CODE HERE\n",
    "\n",
    "optimizer = ## YOUR CODE HERE\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcc6dd-7a02-478f-8427-a2fd75031ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(range(number_epochs)) as iterator:\n",
    "    for epoch in iterator:\n",
    "        running_loss = 0\n",
    "        count = 0\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            image, i = data\n",
    "            image = image.to(device)\n",
    "  \n",
    "            # Forward pass\n",
    "            output, mean, logvar = model(image)\n",
    "            rc_loss = ## YOUR CODE HERE\n",
    "            kl_loss = ## YOUR CODE HERE\n",
    "            loss = rc_loss + beta * kl_loss\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            count += 1\n",
    "        train_loss.append(running_loss/count)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_loss = 0\n",
    "            count = 0\n",
    "            for data in test_loader:\n",
    "                image, i = data\n",
    "                image = image.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output, mean, logvar = model(image)\n",
    "                rc_loss = ## YOUR CODE HERE\n",
    "                kl_loss = ## YOUR CODE HERE\n",
    "                loss = rc_loss + beta * kl_loss\n",
    "                running_loss += loss.item()\n",
    "                count += 1\n",
    "            test_loss.append(running_loss/count)\n",
    "                \n",
    "            iterator.set_postfix_str(f\"Train Loss: {train_loss[-1]:.4f}, Test Loss: {test_loss[-1]:.4f}\")\n",
    "            if epoch % 10 == 0:\n",
    "                rec = to_image(output.cpu().data)\n",
    "                img = to_image(image.cpu().data)\n",
    "                save_image(rec, f\"rec_{epoch}.png\")\n",
    "                save_image(img, f\"img_{epoch}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5479da9-32d0-453b-9459-37742a162d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss)), train_loss, label=\"train_loss\")\n",
    "plt.plot(range(len(test_loss)), test_loss, label=\"test_loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef549954-3ed9-422b-970f-65e1c1a30b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
